#!/usr/bin/env python3
"""
Database Migration: Increase field lengths to prevent truncation errors

This script increases the length of several VARCHAR fields in the link_content_analysis table
to accommodate longer values generated by LLM analysis.

Changes:
- development_stage: VARCHAR(50) -> VARCHAR(200)
- model_used: VARCHAR(50) -> VARCHAR(100)
- extraction_method: VARCHAR(50) -> VARCHAR(100)
- document_type: VARCHAR(20) -> VARCHAR(50)
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv
from loguru import logger
import psycopg2
from psycopg2 import sql

# Add project root to path
sys.path.append(str(Path(__file__).parent))

# Load environment variables
load_dotenv(".env")


def get_database_url():
    """Get database URL from environment variables."""
    db_host = os.getenv("DB_HOST", "localhost")
    db_port = os.getenv("DB_PORT", "5432")
    db_name = os.getenv("DB_NAME", "crypto_analytics")
    db_user = os.getenv("DB_USER", "crypto_user")
    db_password = os.getenv("DB_PASSWORD", "crypto_secure_password_2024")

    return f"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}"


def run_migration():
    """Run the field length migration."""
    database_url = get_database_url()

    # Parse the database URL to get connection parameters
    from urllib.parse import urlparse

    parsed = urlparse(database_url)

    try:
        # Connect to the database
        conn = psycopg2.connect(
            host=parsed.hostname,
            port=parsed.port,
            database=parsed.path[1:],  # Remove leading slash
            user=parsed.username,
            password=parsed.password,
        )
        conn.autocommit = True
        cursor = conn.cursor()

        logger.info("Connected to database successfully")

        # List of field modifications
        field_changes = [
            {
                "field": "development_stage",
                "old_size": "50",
                "new_size": "200",
                "description": "Allow longer development stage descriptions",
            },
            {
                "field": "model_used",
                "old_size": "50",
                "new_size": "100",
                "description": "Allow longer model names",
            },
            {
                "field": "extraction_method",
                "old_size": "50",
                "new_size": "100",
                "description": "Allow longer extraction method names",
            },
            {
                "field": "document_type",
                "old_size": "20",
                "new_size": "50",
                "description": "Allow longer document type names",
            },
        ]

        # Check if table exists
        cursor.execute(
            """
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'link_content_analysis'
            );
        """
        )

        if not cursor.fetchone()[0]:
            logger.error("Table 'link_content_analysis' does not exist!")
            return False

        logger.info("Starting field length migration...")

        # Apply each field change
        for change in field_changes:
            field_name = change["field"]
            new_size = change["new_size"]
            description = change["description"]

            logger.info(f"Updating {field_name} to VARCHAR({new_size}): {description}")

            try:
                # Check current column definition
                cursor.execute(
                    """
                    SELECT data_type, character_maximum_length 
                    FROM information_schema.columns 
                    WHERE table_name = 'link_content_analysis' 
                    AND column_name = %s;
                """,
                    (field_name,),
                )

                result = cursor.fetchone()
                if result:
                    current_type, current_length = result
                    logger.debug(
                        f"Current {field_name}: {current_type}({current_length})"
                    )

                # Alter the column
                alter_sql = sql.SQL(
                    "ALTER TABLE link_content_analysis ALTER COLUMN {} TYPE VARCHAR({})"
                ).format(sql.Identifier(field_name), sql.Literal(int(new_size)))

                cursor.execute(alter_sql)
                logger.success(f"Successfully updated {field_name}")

            except Exception as e:
                logger.error(f"Failed to update {field_name}: {e}")
                return False

        # Verify the changes
        logger.info("Verifying field changes...")
        cursor.execute(
            """
            SELECT column_name, data_type, character_maximum_length 
            FROM information_schema.columns 
            WHERE table_name = 'link_content_analysis' 
            AND column_name IN ('development_stage', 'model_used', 'extraction_method', 'document_type')
            ORDER BY column_name;
        """
        )

        results = cursor.fetchall()
        for column_name, data_type, max_length in results:
            logger.info(f"âœ“ {column_name}: {data_type}({max_length})")

        logger.success("Migration completed successfully!")
        return True

    except Exception as e:
        logger.error(f"Migration failed: {e}")
        return False
    finally:
        if "cursor" in locals():
            cursor.close()
        if "conn" in locals():
            conn.close()


if __name__ == "__main__":
    logger.info("Starting database field length migration...")
    success = run_migration()

    if success:
        logger.success("Migration completed successfully!")
        sys.exit(0)
    else:
        logger.error("Migration failed!")
        sys.exit(1)
